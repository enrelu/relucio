---
title: 'El impacto de la inteligencia artificial en los ataques de ingeniería social'
description: 'La ingeniería social es un conjunto de técnicas utilizadas por los ciberdelincuentes para engañar a las personas y hacer que divulguen información confidencial ...'
pubDate: '2026-01-08'
category: 'General'
tags: []
heroImage: "https://relucio.es/wp-content/uploads/2024/01/1676377340618-1.png"
---

La ingeniería social es un conjunto de técnicas utilizadas por los ciberdelincuentes para engañar a las personas y hacer que divulguen información confidencial o realicen acciones perjudiciales. En este post, discutiremos los tipos más comunes de ataques de ingeniería social y cómo se está usando la inteligencia artificial para mejorar la eficacia de estos.

Los ataques de [phishing](https://en.wikipedia.org/wiki/Phishing) son uno de los tipos más comunes de ataques de ingeniería social. Estos ataques implican el uso de correos electrónicos falsos, mensajes de redes sociales u otros métodos de comunicación electrónica para engañar a los individuos para que divulguen información personal y sensible. El atacante puede usar información recopilada de recursos públicos, especialmente las redes sociales, para crear un mensaje falso creíble que parezca provenir de una persona u organización conocida. Estos ataques pueden tomar diferentes formas como el phishing por correo electrónico, malware, [spear phishing](https://latam.kaspersky.com/resource-center/definitions/spear-phishing), [whaling](https://www.techtarget.com/searchsecurity/definition/whaling), [smishing](https://www.incibe.es/aprendeciberseguridad/smishing) o [vishing](https://en.wikipedia.org/wiki/Voice_phishing).

Los ataques de [pretexting](https://en.wikipedia.org/wiki/Pretexting) implican crear escenarios falsos y creíbles para obtener datos personales de las víctimas. El atacante se basa en pretextos que hacen que la víctima crea y confíe en el agresor. El ataque se realiza generalmente por teléfono, correo electrónico o medios físicos. El pretexto puede ser una oferta para proporcionar servicios o encontrar empleo, solicitar información personal, ayudar a un amigo a acceder a algo o ganar la lotería.

Los ataques de cebo ([baiting](https://easydmarc.com/blog/what-is-baiting-in-cybersecurity-techniques-examples-protection/)) implican atraer a individuos a una trampa. Estos ataques pueden tomar la forma de un archivo adjunto malicioso con un nombre atractivo, un mensaje indicando que se ha ganado algún premio, o el método físico de propagar malware mediante unidades USB infectadas abandonadas en áreas visibles.

El [tailgating o piggybacking](https://ciberseguridad.com/amenzas/tailgating-piggybacking/) implica que los atacantes obtengan acceso a áreas físicas o información restringidas a través de personas autorizadas, ya sea accediendo detrás de esta persona sin que se dé cuenta o engañándola para que directamente le permita acceder.

Con el uso de la inteligencia artificial en el campo de la ingeniería social podemos encontrar nuevas herramientas como el [Voice Cloning](https://www.toptal.com/insights/innovation/voice-clone), [Deepfakes](https://www.fortinet.com/resources/cyberglossary/deepfake) o [Bots](https://www.trustwave.com/en-us/resources/blogs/spiderlabs-blog/interactive-phishing-mark-ii-messenger-chatbot-leveraged-in-a-new-facebook-themed-spam/), que pueden manipular el sonido y las imágenes para engañar a las personas.

La tecnología de clonación de voz es un ejemplo de cómo la inteligencia artificial está siendo utilizada en los ataques de ingeniería social. Los ciberdelincuentes pueden crear una copia digital de la voz de alguien en minutos, lo que puede ser utilizado para engañar a las personas para que crean que están hablando con alguien que no es.

Los deepfakes permite la creación de videos y fotos manipuladas con inteligencia artificial que se utilizan para difundir desinformación y manipular a las personas. Con la ayuda de los deepfakes, los estafadores pueden orquestar ataques de ingeniería social que parecen provenir de un conocido, es decir, alguien en quien confiamos y cuyos motivos no necesitan ser cuestionados.

Por último, un novedoso ataque utiliza chatbots para guiar a las víctimas a través del proceso y darle más credibilidad. El chatbot inicia una conversación en un sitio web legítimo y lleva a la víctima a un sitio de phishing. Un ataque real, según una publicación de [Trustwave](https://www.trustwave.com/en-us/resources/blogs/spiderlabs-blog/interactive-phishing-mark-ii-messenger-chatbot-leveraged-in-a-new-facebook-themed-spam/), comienza con un correo electrónico que advierte a la víctima que su página de Facebook ha infringido las reglas de la comunidad y le pide que haga clic en el botón «Apelar ahora». Se dirige a la víctima a un sitio web que se hace pasar por un chat de soporte de Facebook, donde se le pide que envíe su información personal y la contraseña de la cuenta.

En conclusión, la inteligencia artificial ha mejorado la eficacia de los ataques de ingeniería social. Es importante que las empresas y las personas tomen medidas para protegerse de estos ataques, como la verificación de la autenticidad de los correos electrónicos y las llamadas telefónicas, y la adopción de medidas de seguridad adecuadas. Además, es importante que las empresas inviertan en tecnología de detección y respuesta avanzada para identificar y mitigar los ataques de ingeniería social.

### Deja una respuesta [Cancelar la respuesta](/blog/el-impacto-de-la-inteligencia-artificial-en-los-ataques-de-ingenieria-social#respond)

Tu dirección de correo electrónico no será publicada. Los campos obligatorios están marcados con \*

Comentario \*

Nombre \* 

Correo electrónico \* 

Sitio web 

 Guardar mi nombre, correo electrónico y sitio web en este navegador para la próxima vez que comente

  

Δ
